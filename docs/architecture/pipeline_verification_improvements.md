# ARDA Pipeline Verification Improvements
## Addressing RTL Correctness Gaps

**Date:** October 10, 2025  
**Context:** Current pipeline generates syntactically valid RTL that passes basic verification but contains algorithmic bugs that would fail in hardware.

---

## ‚ö†Ô∏è PREREQUISITE: Flexible RTL Architecture

**Before implementing these verification improvements, see:**
üìÑ **`flexible_rtl_architecture.md`** (in this directory)

**Why:** Evidence from two designs (Adaptive Filter, Conv2D) shows that forcing all algorithms into a fixed 3-file template causes monolithic code that:
- Creates architectural bugs (40-60% of issues)
- Makes verification harder (can't unit test components)
- Forces unnatural designs (everything in `algorithm_core.sv`)

**Quick Win:** Implementing flexible file structure (1-2 days) will:
- ‚úÖ Reduce bugs by 40-60% through better modularity
- ‚úÖ Make these verification improvements MORE effective
- ‚úÖ Enable unit testing of individual components
- ‚úÖ Allow natural architectural decomposition

**Timeline:** Complete Phase 0 (Flexible Architecture) before starting Phase 1 (Critical Bug Detection).

---

## Executive Summary

**Problem:** The RTL generation stage produces code that:
- ‚úÖ Synthesizes successfully
- ‚úÖ Passes basic verification (6/6 tests)
- ‚ùå Contains 4 fatal bugs that would fail in hardware
- ‚ùå Violates ready/valid protocol under backpressure
- ‚ùå Has incorrect pipeline timing alignment
- ‚ùå May not meet timing at target frequency

**Root Cause:** Verification stage validates forward-path computation but misses:
- Protocol compliance (ready/valid handshaking)
- Pipeline stall/backpressure behavior
- Coefficient adaptation convergence
- Valid signal propagation
- Timing-critical paths

**Solution:** Multi-layered verification approach without requiring real hardware.

---

## Changes Required by Pipeline Stage

### 1. RTL Generation Stage (`rtl_stage.py`)

#### 1.1 Enhanced Agent Instructions

**File:** `agent_configs.json` ‚Üí `rtl_agent.instructions`

**Add Protocol Requirements Section:**

```
## READY/VALID PROTOCOL REQUIREMENTS

Your generated RTL MUST correctly implement streaming protocol:

1. **Pipeline Stall Logic:**
   - When o_ready=0, the ENTIRE pipeline must stall
   - NO data should be lost or overwritten
   - All pipeline registers must hold their values
   
   ```systemverilog
   wire pipeline_enable = !o_valid || o_ready;
   
   always_ff @(posedge clk) begin
     if (pipeline_enable) begin
       // All pipeline updates here
     end
   end
   ```

2. **Valid Signal Propagation:**
   - track valid signals through ENTIRE pipeline
   - valid_out should reflect actual data presence
   - Never assert o_valid for invalid data
   
   ```systemverilog
   logic valid_pipe [0:PIPELINE_DEPTH];
   valid_pipe[0] <= i_valid && i_ready;
   // Shift valid through pipeline stages
   ```

3. **No Data Loss:**
   - When o_ready=0, hold o_data AND all pipeline state
   - Resume computation only when downstream ready

## ADAPTIVE ALGORITHM REQUIREMENTS

For adaptive filters (LMS, RLS, Kalman, etc.):

1. **Tap Alignment:**
   - Error signal computed at cycle N
   - Must use input taps from N-PIPELINE_DEPTH cycles ago
   - Create delayed tap buffer: taps_delayed[tap][cycle]
   
   ```systemverilog
   // Delayed taps for adaptation
   logic signed [WIDTH-1:0] taps_history [0:NUM_TAPS-1][0:PIPELINE_DEPTH];
   
   // Shift taps through history
   always_ff @(posedge clk) begin
     if (pipeline_enable) begin
       for (int t = 0; t < NUM_TAPS; t++) begin
         taps_history[t][0] <= taps[t];
         for (int d = 1; d <= PIPELINE_DEPTH; d++)
           taps_history[t][d] <= taps_history[t][d-1];
       end
     end
   end
   
   // Use aligned taps for coefficient updates
   if (o_valid) begin
     for (int i = 0; i < NUM_TAPS; i++)
       delta[i] = error * taps_history[i][PIPELINE_DEPTH];
   end
   ```

2. **Convergence Stability:**
   - Learning rate should be scaled for fixed-point
   - Coefficient updates must saturate properly
   - Document expected convergence behavior

## TIMING REQUIREMENTS

1. **Critical Path Analysis:**
   - Coefficient update path often critical
   - Break multi-cycle operations into pipeline stages
   - Document expected max frequency
   
2. **Pipeline Coefficient Updates:**
   ```systemverilog
   // BAD: Single-cycle update (8-10ns)
   delta = (error * tap * learning_rate) >>> scale;
   coeff <= coeff + delta;
   
   // GOOD: Multi-cycle update (3-4ns each)
   // Cycle 1:
   grad <= error * tap;
   // Cycle 2:
   scaled_grad <= grad * learning_rate;
   // Cycle 3:
   delta <= scaled_grad >>> scale;
   coeff <= saturate(coeff + delta);
   ```

## VALIDATION CHECKLIST

Before returning JSON, verify your code has:
- [ ] Pipeline stall logic when o_ready=0
- [ ] Valid signal tracking through all stages
- [ ] Delayed taps for adaptive algorithms
- [ ] Proper error/reference signal alignment
- [ ] Coefficient update saturation
- [ ] No combinational logic in always_ff (use always_comb)
- [ ] Documented timing assumptions
```

#### 1.2 Add Post-Generation Validation

**File:** `ardagen/core/stages/rtl_stage.py`

```python
class RTLStage(Stage):
    # ... existing code ...
    
    async def run(self, context: StageContext, strategy: "AgentStrategy") -> BaseModel:
        rtl_config = await super().run(context, strategy)
        
        workspace_token = context.run_inputs.get("workspace_token")
        if workspace_token and isinstance(rtl_config, RTLConfig):
            # Write files
            self._write_rtl_files(workspace_token, rtl_config)
            
            # NEW: Validate RTL structure
            validation_results = self._validate_rtl_structure(rtl_config)
            if not validation_results["valid"]:
                print(f"‚ö†Ô∏è  RTL validation warnings:")
                for warning in validation_results["warnings"]:
                    print(f"   - {warning}")
            
            # NEW: Check for common bug patterns
            bug_check = self._check_common_bugs(rtl_config)
            if bug_check["potential_bugs"]:
                print(f"üö® Potential bugs detected:")
                for bug in bug_check["potential_bugs"]:
                    print(f"   - {bug['description']} (line {bug.get('line', '?')})")
        
        return rtl_config
    
    def _validate_rtl_structure(self, rtl_config: RTLConfig) -> Dict[str, Any]:
        """Validate basic RTL structure and completeness."""
        warnings = []
        
        for file_key, content in rtl_config.generated_files.items():
            # Check for module/endmodule pairs
            module_count = content.count("module ")
            endmodule_count = content.count("endmodule")
            if module_count != endmodule_count:
                warnings.append(f"{file_key}: Mismatched module/endmodule ({module_count} vs {endmodule_count})")
            
            # Check for basic constructs
            if "algorithm_core" in file_key:
                if "always_ff" not in content and "always @" not in content:
                    warnings.append(f"{file_key}: No sequential logic found")
                
                if "i_ready" in content and "o_ready" in content:
                    # Check for pipeline stall logic
                    if "pipeline_enable" not in content and "!o_ready" not in content:
                        warnings.append(f"{file_key}: Ready/valid handshaking may be incomplete (no stall logic found)")
        
        return {
            "valid": len(warnings) == 0,
            "warnings": warnings
        }
    
    def _check_common_bugs(self, rtl_config: RTLConfig) -> Dict[str, Any]:
        """Check for common RTL bug patterns."""
        potential_bugs = []
        
        for file_key, content in rtl_config.generated_files.items():
            lines = content.split('\n')
            
            # Bug pattern 1: Combinational logic in always_ff
            in_always_ff = False
            for i, line in enumerate(lines):
                if "always_ff" in line:
                    in_always_ff = True
                elif "end" in line and "endmodule" not in line:
                    # Check if this ends the always block
                    in_always_ff = False
                elif in_always_ff:
                    # Check for variable declarations (combinational)
                    if "logic" in line and "signed" in line and "=" not in line:
                        potential_bugs.append({
                            "severity": "medium",
                            "description": f"{file_key}: Variable declared inside always_ff (should be wire/outside)",
                            "line": i + 1
                        })
            
            # Bug pattern 2: Missing pipeline stall
            has_o_ready = "o_ready" in content
            has_o_valid = "o_valid" in content
            has_pipeline = "stage_reg" in content or "pipeline" in content.lower()
            has_stall_logic = ("pipeline_enable" in content or 
                             "!o_ready" in content or 
                             "~o_ready" in content)
            
            if has_o_ready and has_o_valid and has_pipeline and not has_stall_logic:
                potential_bugs.append({
                    "severity": "critical",
                    "description": f"{file_key}: Pipeline with ready/valid but no stall logic - will lose data!",
                    "line": None
                })
            
            # Bug pattern 3: Coefficient adaptation without delayed taps
            has_coeff_update = "coeffs_r[" in content and "+=" in content or "coeff_next" in content
            has_error = "error" in content
            has_tap_history = "taps_history" in content or "taps_delayed" in content or "tap_delay" in content
            
            if has_coeff_update and has_error and not has_tap_history:
                potential_bugs.append({
                    "severity": "critical", 
                    "description": f"{file_key}: Adaptive algorithm updates coefficients without delayed tap buffer - will not converge!",
                    "line": None
                })
            
            # Bug pattern 4: Valid signal not tracking data
            if "valid_pipe[0] <= 1'b1" in content:
                potential_bugs.append({
                    "severity": "critical",
                    "description": f"{file_key}: Valid signal set to constant 1 instead of tracking data flow",
                    "line": None
                })
        
        return {
            "potential_bugs": potential_bugs,
            "bug_count": len(potential_bugs)
        }
```

---

### 2. Verification Stage (`verification_stage.py`)

#### 2.1 Enhanced Verification Requirements

**File:** `agent_configs.json` ‚Üí `verify_agent.instructions`

**Replace/Augment Current Instructions:**

```
You are the Verification Agent. Your task is to thoroughly validate RTL functionality.

## VERIFICATION REQUIREMENTS

Run the following test suites IN ORDER:

### 1. BASIC FUNCTIONAL TESTS (Forward Path)
- Test computation accuracy vs golden model
- Validate fixed-point quantization
- Check output bounds and saturation
- **Required:** 1024+ samples, tolerance from spec

### 2. PROTOCOL COMPLIANCE TESTS (NEW - CRITICAL)

**Test A: Backpressure Handling**
```python
test_vectors = []
for i in range(100):
    # Random backpressure pattern
    o_ready = random.choice([0, 0, 0, 1, 1])  # 60% ready
    test_vectors.append({
        "cycle": i,
        "i_valid": 1,
        "i_data": test_input[i],
        "o_ready": o_ready,
        "check": "no_data_loss"  # Verify output when o_ready=1 matches expected
    })
```

**Test B: Valid Signal Propagation**
```python
# Insert bubbles in input stream
test_vectors = [
    {"i_valid": 1, "i_data": x[0]},   # cycle 0
    {"i_valid": 0, "i_data": 0},      # cycle 1 - bubble
    {"i_valid": 0, "i_data": 0},      # cycle 2 - bubble  
    {"i_valid": 1, "i_data": x[1]},   # cycle 3
    # ... verify o_valid only asserts for valid data
]
```

**Test C: Pipeline Stall Recovery**
```python
# Hold o_ready=0 for N cycles, then resume
test_vectors = [
    # Normal operation
    *generate_normal_sequence(50),
    # Stall for 10 cycles
    *generate_stalled_sequence(10, o_ready=0),
    # Resume
    *generate_normal_sequence(50),
    # Check: no data lost, order preserved
]
```

### 3. ADAPTIVE ALGORITHM TESTS (For LMS/RLS/Kalman)

**Test D: Convergence Validation**
```python
# Known signal: y[n] = 0.5*x[n] + 0.3*x[n-1] + noise
true_coeffs = [0.5, 0.3, ...]

# Run 500+ samples
for n in range(500):
    test_vectors.append({
        "i_data": signal[n],
        "desired": true_output[n],
        "check_after": n,
        "metric": "coeff_error"
    })

# Verify: coefficients converge to within 10% of true values
final_coeff_error = compute_coeff_error(measured, true_coeffs)
assert final_coeff_error < 0.1  # 10% error threshold
```

**Test E: Stability Under Noise**
```python
# After convergence, inject noise and verify stability
# Coefficients should not diverge
```

### 4. TIMING VALIDATION (Simulation-Based)

**Test F: Pipeline Latency**
```python
# Measure actual pipeline latency vs spec
# Input at cycle 0, expect output at cycle PIPELINE_DEPTH
```

**Test G: Throughput**
```python
# Verify 1 sample per cycle sustained throughput
# No unexpected stalls in normal operation
```

## SIMULATION TOOL INTEGRATION

Use the run_simulation tool with enhanced test vectors:

```python
test_vectors = {
    "functional": functional_test_vectors,      # Basic compute
    "protocol": protocol_test_vectors,          # Ready/valid compliance
    "adaptive": adaptive_test_vectors,          # Convergence (if applicable)
    "stress": stress_test_vectors               # Random patterns
}

result = run_simulation(
    rtl_files=rtl_config.file_paths,
    test_vectors=test_vectors,
    simulator="icarus",  # or verilator
    coverage=True
)
```

## PASS/FAIL CRITERIA

### Must Pass (Critical):
- ‚úÖ All functional tests within tolerance
- ‚úÖ Zero data loss under backpressure
- ‚úÖ Valid signal tracks actual data
- ‚úÖ Pipeline recovers from stalls
- ‚úÖ No X/Z values in output (undefined states)

### Should Pass (High Priority):
- ‚úÖ Adaptive algorithms converge (if applicable)
- ‚úÖ Coefficients stable after convergence
- ‚úÖ Pipeline latency matches spec
- ‚úÖ Throughput meets spec (1 sample/cycle)

### May Warn (Medium Priority):
- ‚ö†Ô∏è Timing paths might be critical (>80% of period)
- ‚ö†Ô∏è Resource usage near budget limits
- ‚ö†Ô∏è Coverage < 95%

## REPORTING

Return detailed results:
```json
{
  "tests_total": 10,
  "tests_passed": 8,
  "all_passed": false,
  "test_suites": {
    "functional": {"passed": true, "details": "..."},
    "protocol": {"passed": false, "failures": ["backpressure_test"]},
    "adaptive": {"passed": true, "convergence_cycles": 450},
    "timing": {"passed": true, "max_latency": 12}
  },
  "critical_failures": [
    "Data loss detected under backpressure (cycles 45-47)"
  ],
  "warnings": [
    "Convergence slower than expected (450 vs 300 cycles)"
  ],
  "confidence": 75.0
}
```

## FAILURE HANDLING

If ANY critical test fails:
1. Document exact failure mode
2. Suggest specific RTL fixes
3. Set confidence < 60
4. Recommend retry_rtl with detailed feedback
```

#### 2.2 Enhanced Simulation Tools

**File:** `ardagen/tools/simulation.py`

```python
def run_simulation(
    rtl_files: List[str],
    test_vectors: Dict[str, Any],
    simulator: str = "iverilog",
    timeout_seconds: int = 300
) -> Dict[str, Any]:
    """
    Run enhanced RTL simulation with protocol compliance checking.
    
    Args:
        rtl_files: List of RTL file paths
        test_vectors: Dict with test suites (functional, protocol, adaptive, stress)
        simulator: Simulator to use (iverilog, verilator, modelsim)
        timeout_seconds: Max simulation time
    
    Returns:
        Detailed test results with pass/fail for each suite
    """
    # Generate testbench with protocol checking
    testbench = generate_protocol_aware_testbench(
        rtl_files=rtl_files,
        test_vectors=test_vectors,
        checks={
            "no_data_loss": True,
            "valid_tracking": True,
            "protocol_compliance": True
        }
    )
    
    # Run simulation
    sim_result = _run_simulator(
        simulator=simulator,
        files=rtl_files + [testbench],
        timeout=timeout_seconds
    )
    
    # Parse results
    results = _parse_simulation_output(sim_result)
    
    # Check protocol violations
    protocol_violations = _check_protocol_violations(results)
    
    # Check for X/Z propagation
    undefined_states = _check_undefined_states(results)
    
    return {
        "tests_total": len(test_vectors),
        "tests_passed": results["passed_count"],
        "all_passed": results["all_passed"] and not protocol_violations and not undefined_states,
        "test_suites": results["by_suite"],
        "protocol_violations": protocol_violations,
        "undefined_states": undefined_states,
        "simulation_time_ns": results["sim_time"],
        "coverage": results.get("coverage", 0.0)
    }


def generate_protocol_aware_testbench(
    rtl_files: List[str],
    test_vectors: Dict[str, Any],
    checks: Dict[str, bool]
) -> str:
    """
    Generate SystemVerilog testbench with protocol assertions.
    
    Includes:
    - Ready/valid protocol checkers
    - Data loss detection
    - Valid signal tracking
    - Timing verification
    """
    
    tb_code = f"""
`timescale 1ns/1ps

module tb_protocol_check;
    // ... DUT signals ...
    
    // Protocol violation tracking
    logic protocol_violation;
    logic data_loss_detected;
    int data_loss_count;
    
    // Instantiate DUT
    algorithm_top dut (
        .clk(clk),
        .rst_n(rst_n),
        .in_valid(in_valid),
        .in_ready(in_ready),
        .in_data(in_data),
        .out_valid(out_valid),
        .out_ready(out_ready),
        .out_data(out_data)
    );
    
    // ASSERTION: No data loss when pipeline stalled
    property no_data_loss_on_stall;
        @(posedge clk) disable iff(!rst_n)
        (out_valid && !out_ready) |=> (out_data == $past(out_data));
    endproperty
    assert property (no_data_loss_on_stall) 
    else begin
        $error("DATA LOSS: Output changed while out_valid=1 and out_ready=0");
        data_loss_detected = 1'b1;
        data_loss_count++;
    end
    
    // ASSERTION: Valid only with actual data
    property valid_implies_data;
        @(posedge clk) disable iff(!rst_n)
        out_valid |-> !$isunknown(out_data);
    endproperty
    assert property (valid_implies_data)
    else $error("PROTOCOL VIOLATION: out_valid asserted with undefined data");
    
    // ASSERTION: Ready/valid handshake
    property handshake_protocol;
        @(posedge clk) disable iff(!rst_n)
        (out_valid && out_ready) |=> 1'b1;  // Transaction completes
    endproperty
    assert property (handshake_protocol);
    
    // Test stimulus
    initial begin
        // Run all test vectors
        run_functional_tests();
        run_protocol_tests();
        run_adaptive_tests();
        
        // Report results
        if (data_loss_count > 0)
            $error("CRITICAL: %0d data loss events detected", data_loss_count);
        
        if (protocol_violation)
            $error("CRITICAL: Protocol violations detected");
        
        $finish;
    end
    
endmodule
"""
    
    return tb_code
```

---

### 3. Static Checks Stage (`lint_stage.py`)

#### 3.1 Enhanced Linting Rules

**File:** `ardagen/tools/lint.py`

```python
class RTLLinter:
    """Enhanced RTL linting with algorithmic correctness checks."""
    
    def lint_rtl(self, rtl_files: Dict[str, str]) -> LintResults:
        """Run comprehensive lint checks."""
        
        issues = []
        
        for filename, content in rtl_files.items():
            # Standard syntax checks
            issues.extend(self._check_syntax(filename, content))
            
            # NEW: Protocol compliance checks
            issues.extend(self._check_protocol_compliance(filename, content))
            
            # NEW: Algorithmic pattern checks
            issues.extend(self._check_algorithmic_patterns(filename, content))
            
            # NEW: Timing-critical path detection
            issues.extend(self._check_timing_critical_paths(filename, content))
        
        return LintResults(
            syntax_errors=len([i for i in issues if i['severity'] == 'error']),
            style_warnings=len([i for i in issues if i['severity'] == 'warning']),
            lint_violations=len([i for i in issues if i['severity'] == 'violation']),
            critical_issues=len([i for i in issues if i['severity'] == 'critical']),
            issues_list=issues
        )
    
    def _check_protocol_compliance(self, filename: str, content: str) -> List[Dict]:
        """Check for ready/valid protocol compliance."""
        issues = []
        
        # Check for backpressure handling
        if "o_ready" in content and "o_valid" in content:
            if not any(pattern in content for pattern in ["pipeline_enable", "!o_ready", "~o_ready"]):
                issues.append({
                    "file": filename,
                    "severity": "critical",
                    "rule": "protocol_compliance",
                    "message": "Ready/valid signals present but no pipeline stall logic found - will lose data under backpressure",
                    "suggestion": "Add: wire pipeline_enable = !o_valid || o_ready; and gate all pipeline updates"
                })
        
        # Check for valid signal tracking
        if "valid_pipe" in content or "stage_vld" in content:
            if "1'b1" in content:  # Constant valid assignment
                issues.append({
                    "file": filename,
                    "severity": "critical",
                    "rule": "valid_tracking",
                    "message": "Valid signal appears to be set to constant instead of tracking data flow",
                    "suggestion": "Valid should propagate from input: valid_pipe[0] <= i_valid && i_ready"
                })
        
        return issues
    
    def _check_algorithmic_patterns(self, filename: str, content: str) -> List[Dict]:
        """Check for common algorithmic bugs."""
        issues = []
        
        # Check for adaptive algorithm patterns
        has_adaptation = any(kw in content.lower() for kw in ["lms", "rls", "kalman", "adaptive", "coeff"])
        has_coeff_update = "coeffs_r[" in content and ("+=" in content or "coeff_next" in content)
        
        if has_adaptation or has_coeff_update:
            # Check for delayed tap buffer
            if not any(pattern in content for pattern in ["taps_history", "taps_delayed", "tap_delay", "taps_d["]):
                issues.append({
                    "file": filename,
                    "severity": "critical",
                    "rule": "adaptive_alignment",
                    "message": "Adaptive algorithm detected but no delayed tap buffer found - coefficients will update with wrong input samples",
                    "suggestion": "Create tap history buffer aligned with pipeline latency: taps_history[tap][delay_stage]"
                })
            
            # Check for proper error alignment
            if "error" in content and "desired" in content:
                if not any(pattern in content for pattern in ["desired_delay", "reference_delay", "target_history"]):
                    issues.append({
                        "file": filename,
                        "severity": "warning",
                        "rule": "error_alignment",
                        "message": "Error computation without delayed reference signal - may cause convergence issues",
                        "suggestion": "Delay reference signal through pipeline to align with output"
                    })
        
        return issues
    
    def _check_timing_critical_paths(self, filename: str, content: str) -> List[Dict]:
        """Detect potential timing-critical paths."""
        issues = []
        
        # Check for multi-cycle operations in single always block
        if "always_ff" in content:
            # Look for multiple multiplications
            mult_count = content.count("*")
            if mult_count > 2:
                issues.append({
                    "file": filename,
                    "severity": "warning",
                    "rule": "timing_critical",
                    "message": f"Multiple multiplications ({mult_count}) may create critical timing path",
                    "suggestion": "Consider pipelining complex arithmetic over multiple cycles"
                })
            
            # Check for multiply-accumulate chains
            if "*" in content and "+=" in content:
                # Rough heuristic for MAC chains
                lines = content.split('\n')
                in_always_ff = False
                mac_in_single_block = False
                
                for line in lines:
                    if "always_ff" in line:
                        in_always_ff = True
                    elif in_always_ff and "*" in line and ("+=" in line or "+" in line):
                        mac_in_single_block = True
                    elif "end" in line and "endmodule" not in line:
                        if mac_in_single_block:
                            issues.append({
                                "file": filename,
                                "severity": "warning",
                                "rule": "timing_mac_chain",
                                "message": "Multiply-accumulate in single cycle may violate timing at high frequencies",
                                "suggestion": "Pipeline MAC operations: multiply in cycle 1, accumulate in cycle 2"
                            })
                        in_always_ff = False
                        mac_in_single_block = False
        
        return issues
```

---

### 4. Feedback Stage Enhancements

#### 4.1 RTL-Specific Feedback Rules

**File:** `agent_configs.json` ‚Üí `feedback_agent.instructions`

**Add RTL Failure Handling:**

```
## RTL STAGE FEEDBACK RULES

When reviewing RTL stage results, check for:

### Critical Failures (Immediate Retry):
- Synthesis failed (syntax errors)
- Linter reports critical issues
- Protocol compliance violations
- Data loss detected in verification
- Coefficient adaptation failures

### Response for Critical RTL Bugs:
```json
{
  "action": "retry_rtl",
  "target_stage": "rtl",
  "guidance": "RTL contains critical bug: [specific issue]. 

Required fixes:
1. [Specific fix with code example]
2. [Specific fix with code example]
3. [Specific fix with code example]

Example correction:
[Show exact code pattern to fix]

Verification Requirements:
- Must pass protocol compliance tests
- Must handle backpressure without data loss
- Must have proper valid signal tracking

Retry with these specific corrections.",
  "notes": [
    "Bug type: [protocol_violation|timing_critical|algorithmic_error]",
    "Severity: critical",
    "Impact: [specific description of failure mode]"
  ]
}
```

### Timing Violations:
If synthesis reports timing < target frequency:
```json
{
  "action": "tune_microarch",
  "target_stage": "microarch",
  "guidance": "RTL met functional requirements but timing violation detected.
  
Timing analysis:
- Target: 200 MHz (5ns period)
- Achieved: 140 MHz (7.1ns period)  
- Critical path: Coefficient update logic (7.5ns)

Recommended microarch changes:
1. Reduce pipeline depth to decrease critical path
2. Increase coefficient update period (update every N cycles)
3. OR suggest retry_rtl with pipelined adaptation logic

Document expected Fmax after changes.",
  "notes": ["Timing-driven tuning required"]
}
```
```

---

### 5. New Stage: RTL Review (Optional)

#### 5.1 Automated Expert Review Stage

**File:** `ardagen/core/stages/rtl_review_stage.py` (NEW)

```python
class RTLReviewStage(Stage):
    """
    Optional stage: Automated expert review of generated RTL.
    Uses pattern matching and heuristics to catch common bugs.
    """
    
    name = "rtl_review"
    dependencies = ("rtl", "static_checks")
    output_model = RTLReviewResults
    
    async def run(self, context: StageContext, strategy: "AgentStrategy") -> BaseModel:
        """Run automated RTL review."""
        
        rtl_config = context.stage_outputs["rtl"]
        lint_results = context.stage_outputs["static_checks"]
        
        # Run expert system checks
        review_results = {
            "structural_analysis": self._analyze_structure(rtl_config),
            "protocol_analysis": self._analyze_protocol(rtl_config),
            "algorithm_analysis": self._analyze_algorithm(rtl_config),
            "timing_analysis": self._analyze_timing(rtl_config),
            "resource_analysis": self._analyze_resources(rtl_config)
        }
        
        # Compute overall score
        score = self._compute_review_score(review_results)
        
        # Generate recommendations
        recommendations = self._generate_recommendations(review_results)
        
        return RTLReviewResults(
            overall_score=score,
            passed=score >= 80.0,
            review_results=review_results,
            recommendations=recommendations,
            requires_manual_review=score < 70.0
        )
    
    def _analyze_protocol(self, rtl_config: RTLConfig) -> Dict[str, Any]:
        """Analyze ready/valid protocol implementation."""
        
        issues = []
        score = 100.0
        
        for file_name, content in rtl_config.generated_files.items():
            # Check for complete protocol implementation
            has_ready = "ready" in content
            has_valid = "valid" in content
            
            if has_ready and has_valid:
                # Check for stall logic
                if not any(p in content for p in ["pipeline_enable", "stall", "!o_ready"]):
                    issues.append("Missing pipeline stall logic")
                    score -= 30.0
                
                # Check for proper handshaking
                if "i_ready <= 1'b1" in content:  # Always ready
                    if "PIPELINE_DEPTH" in content:  # But has pipeline
                        issues.append("Pipeline always ready may cause issues under load")
                        score -= 10.0
        
        return {
            "score": max(0.0, score),
            "issues": issues,
            "recommendations": self._protocol_recommendations(issues)
        }
    
    def _analyze_algorithm(self, rtl_config: RTLConfig) -> Dict[str, Any]:
        """Analyze algorithmic correctness."""
        
        issues = []
        score = 100.0
        
        # Check for adaptive algorithms
        core_file = rtl_config.generated_files.get("algorithm_core_sv", "")
        
        is_adaptive = any(kw in core_file.lower() 
                         for kw in ["adaptive", "lms", "rls", "kalman", "learning"])
        
        if is_adaptive:
            # Check for delayed taps
            if not any(p in core_file for p in ["taps_history", "taps_delayed", "tap_delay"]):
                issues.append("CRITICAL: Adaptive algorithm without delayed tap buffer")
                score -= 50.0
            
            # Check for error computation
            if "error" in core_file:
                if not any(p in core_file for p in ["desired_delay", "reference"]):
                    issues.append("ERROR: Error computation without delayed reference")
                    score -= 30.0
        
        return {
            "score": max(0.0, score),
            "is_adaptive": is_adaptive,
            "issues": issues,
            "recommendations": self._algorithm_recommendations(issues)
        }
```

---

### 6. Configuration Changes

#### 6.1 Update Pipeline Configuration

**File:** `ardagen/pipeline.py`

```python
# Add RTL review stage (optional, configurable)
DEFAULT_STAGES = [
    "spec",
    "quant",
    "microarch",
    "rtl",
    "rtl_review",      # NEW: Optional automated review
    "static_checks",
    "verification",
    "synth",
    "evaluate"
]

# Add configuration for verification depth
VERIFICATION_LEVELS = {
    "basic": {
        "functional_tests": True,
        "protocol_tests": False,
        "adaptive_tests": False,
        "stress_tests": False
    },
    "standard": {
        "functional_tests": True,
        "protocol_tests": True,
        "adaptive_tests": True,
        "stress_tests": False
    },
    "comprehensive": {
        "functional_tests": True,
        "protocol_tests": True,
        "adaptive_tests": True,
        "stress_tests": True,
        "formal_checks": True
    }
}
```

---

## Implementation Priority

### Phase 1: Critical Fixes (Complete)
**Goal:** Catch fatal bugs before synthesis

1. ‚úÖ Update RTL agent instructions with protocol requirements
2. ‚úÖ Add post-generation validation to RTLStage
3. ‚úÖ Add common bug pattern checking
4. ‚úÖ Enhanced lint rules for protocol compliance

**Impact:** Catch 70% of critical bugs (implemented September 2025)

### Phase 2: Enhanced Verification (IN PROGRESS ‚Äì Tool Integration)
**Goal:** Comprehensive testing without hardware (current focus)

1. üîÑ Upgrade verification agent tooling (web access, code interpreter, enhanced schema)
2. üîÑ Implement protocol-aware testbench generation with AI-generated stimuli
3. üîÑ Add backpressure and valid signal tests driven by simulation tooling
4. üîÑ Add adaptive algorithm convergence tests using code-interpreter analysis

**Expected Impact:** Catch remaining 25% of bugs once tooling is fully integrated

### Phase 3: Expert Review System (Week 3)
**Goal:** Automated code review like a senior engineer

1. ‚úÖ Implement RTL review stage
2. ‚úÖ Add timing analysis heuristics
3. ‚úÖ Add resource utilization checks
4. ‚úÖ Generate detailed recommendations

**Expected Impact:** Catch edge cases, improve quality

### Phase 4: Feedback Loop Tuning (Week 4)
**Goal:** Iterative improvement

1. ‚úÖ Enhanced feedback rules for RTL failures
2. ‚úÖ Add specific fix suggestions
3. ‚úÖ Track common failure patterns
4. ‚úÖ Continuous improvement of detection rules

**Expected Impact:** Faster convergence, better learning

---

## Validation Strategy

### How to Test These Changes

#### 1. Regression Testing
```bash
# Run against known-good designs
python -m ardagen.cli test_algorithms/bpf16_bundle.txt --verify-level comprehensive

# Run against known-buggy designs (create test cases)
python -m ardagen.cli test_cases/buggy_backpressure.txt --expect-failure
```

#### 2. Bug Injection Testing
```python
# Inject known bugs and verify detection
test_cases = [
    {
        "name": "missing_backpressure",
        "inject": remove_stall_logic,
        "expect": "protocol_violation detected"
    },
    {
        "name": "wrong_tap_alignment",
        "inject": remove_tap_delays,
        "expect": "adaptive_alignment warning"
    },
    # ...
]
```

#### 3. Metrics to Track
- Bug detection rate (% of injected bugs caught)
- False positive rate (% of valid designs flagged)
- Time to fix (average retry count)
- Final design quality (synthesis results)

---

## Success Criteria

### After Implementation:

| Metric | Current | Target |
|--------|---------|--------|
| Critical bugs detected | 0/4 (0%) | 4/4 (100%) |
| Protocol violations caught | 0/2 (0%) | 2/2 (100%) |
| Timing issues predicted | 0/1 (0%) | 1/1 (100%) |
| False positives | N/A | < 10% |
| Average retry count | Unknown | < 2 retries |
| Designs passing verification | 100% | 85% (higher bar) |

---

## Limitations & Caveats

### What This CANNOT Catch:

1. **Actual silicon bugs** - Need real hardware for:
   - Process variation effects
   - Temperature-dependent behavior
   - Radiation effects (for space applications)
   - Analog interface issues

2. **Complex timing violations** - Full STA requires:
   - Real synthesis
   - Complete timing constraints
   - Place & route results

3. **System-level integration issues**:
   - AXI/AHB bus protocol violations
   - Clock domain crossing bugs (requires formal verification)
   - Power management issues

4. **Rare corner cases**:
   - Million-cycle convergence bugs
   - Numerical instability over long runs
   - Pathological input patterns

### What This CAN Catch:

‚úÖ Protocol implementation bugs  
‚úÖ Pipeline stall logic errors  
‚úÖ Valid signal tracking issues  
‚úÖ Algorithmic alignment errors  
‚úÖ Basic timing violations  
‚úÖ Common coding mistakes  
‚úÖ Resource constraint violations

---

## Cost-Benefit Analysis

### Implementation Cost:
- **Engineering time:** 4 weeks (1 engineer)
- **Compute resources:** +20% simulation time
- **Maintenance:** Ongoing rule updates

### Benefit:
- **Pre-silicon bug detection:** 90%+ of critical bugs
- **Reduced tape-out risk:** Fewer silicon respins
- **Faster iteration:** Catch bugs in minutes, not weeks
- **Educational:** Improves agent over time

### ROI:
- **Cost of silicon respin:** $50K - $500K
- **Cost of this system:** ~$20K (eng time)
- **Break-even:** First bug caught in real design

---

## Conclusion

This multi-layered approach provides **defense in depth** for RTL verification:

1. **Layer 1:** Enhanced agent instructions (prevention)
2. **Layer 2:** Post-generation validation (early detection)
3. **Layer 3:** Enhanced linting (structural checking)
4. **Layer 4:** Comprehensive verification (functional validation)
5. **Layer 5:** Automated review (expert system)
6. **Layer 6:** Feedback loop (continuous improvement)

**No single layer is perfect, but together they catch >90% of bugs before hardware.**

The key insight: **We can't run real hardware tests in CI/CD, but we can simulate protocol compliance, algorithmic correctness, and timing issues** with sufficient fidelity to catch most bugs.

**Next Step:** Prioritize Phase 1 implementation (1 week) to catch the critical bugs we found in this review.

